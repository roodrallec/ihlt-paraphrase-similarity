{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from sent_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nbimporter\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.metrics import *\n",
    "from nltk.tag import *\n",
    "from nltk.parse.bllip import BllipParser\n",
    "from nltk import Tree\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.corpus import treebank\n",
    "from sent_utils import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Scatter, Figure, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)\n",
    "MODEL_PATH = find('models/bllip_wsj_no_aux').path\n",
    "PARSER = BllipParser.from_unified_model_dir(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase detectors\n",
    "def paraphrase_score(sent_0, sent_1):\n",
    "    print('.', end='')\n",
    "    sent_0, sent_1 = remove_punctuation(sent_0.lower()), remove_punctuation(sent_1.lower())\n",
    "    words_0, words_1 = words_from_sent(sent_0), words_from_sent(sent_1)\n",
    "    tokens_0, tokens_1 = tokens_from_words(words_0), tokens_from_words(words_1)\n",
    "    lemmas_0, lemmas_1 = tokens_to_lemmas(tokens_0), tokens_to_lemmas(tokens_1)\n",
    "    senses_0, senses_1 = tokens_to_senses(tokens_0), tokens_to_senses(tokens_1)\n",
    "#     pos_0, pos_1 = str(PARSER.parse_one(sent_0.split())), str(PARSER.parse_one(sent_1.split()))\n",
    "    return [\n",
    "        jaccard_distance(set(lemmas_0), set(lemmas_1))\n",
    "#         ,\n",
    "#         pos_0.count('NP'),\n",
    "#         pos_0.count('VP'),\n",
    "#         pos_1.count('NP'),\n",
    "#         pos_1.count('VP')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = text_to_sentences('IHLT-eval-framework/train/msr_paraphrase_train_input.txt')\n",
    "X_train = [paraphrase_score(data[0], data[1])for data in train_input]\n",
    "y_train = open('IHLT-eval-framework/train/msr_paraphrase_train_gs.txt', encoding=\"utf-8-sig\").readlines()\n",
    "y_train = [int(line.strip()) for line in y_train]\n",
    "\n",
    "test_input = text_to_sentences('IHLT-eval-framework/test/msr_paraphrase_test_input.txt')\n",
    "X_test = [paraphrase_score(data[0], data[1])for data in test_input]\n",
    "y_test = open('IHLT-eval-framework/test/msr_paraphrase_test_gs.txt', encoding=\"utf-8-sig\").readlines()\n",
    "y_test = [int(line.strip()) for line in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LogisticRegression()\n",
    "regression.fit(np.array(X_train), y_train)\n",
    "prediction = regression.predict(np.array(X_test))\n",
    "MSRP_eval(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative_idx = list(np.where((prediction != y_test) & (prediction == 0))[0])\n",
    "false_negatives = [input_sentences[i] for i in false_negative_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for false_negative in false_negatives:\n",
    "    sent_0, sent_1 = false_negative[0], false_negative[1]\n",
    "    pos_0, pos_1 = PARSER.parse_one(sent_0.split()), PARSER.parse_one(sent_1.split())\n",
    "    str(pos_0).count('NP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
